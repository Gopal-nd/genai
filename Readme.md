# GenAI

gen ai

trryst

[Google Paper](https://arxiv.org/pdf/1706.03762)


## openAI
GPT = (Geneative Pretrained Transformer)   works on tarained data
chatGPT =  (GPT + aiAgent) aiAgent will give the current details to gpt
 
## how an llm works

it works on the transformer (google paper)

1. Phase 1

convert the text -> tokens 

[tokenizer](tiktokenizer.com)

vector Embeddings => they will give  the Symentic Meaning

vector embedding will make the 3d graph and place the different words in the x,y,z positions


[vector visualizer view](https://projector.tensorflow.org/)

Positionl Encoding

text = "people set on chair"
text = "chair set on people" 

there is difference in the both text

this to get the position of tokens

self evoluation
tokens talk to each other to adjust

(one head and multi head)

here there will be chance to change the vector embeding to make proper symentic meaning


next is it will be send the neural network




## woking phases

1. training phase

in taraing ai  will give the output and the loss calculated and used to train in backend
 eg. asking 2+2 if u give wrong ans , it will hint of answer 


2. inferencing phase

    the linear will give the heigest probility (temperature)










